#!/usr/bin/env python3

"""
Apply Trained GEFS ML Model to New Data

This script demonstrates how to load a previously trained model and apply it to new forecast data.
The model and its metadata (including feature configuration) are loaded automatically.

Usage:
    python apply_trained_model.py

Requirements:
    - Trained model files in 'models/' directory (generated by gefs_ml_trainer.py)
    - New forecast and NBM data in the same format as training data
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys

# Import the model loading functions from the training script
from gefs_ml_trainer import load_model_and_metadata, apply_model_to_new_data

def load_new_data_example():
    """
    Load new forecast and NBM data for prediction.
    
    This is an example - replace with your actual data loading logic.
    The data format should match the training data structure.
    """
    
    # Example: Load new forecast data
    # In practice, this would be your new GEFS forecast files
    forecast_file = "data/forecast/f024/KSLC_2020_2025_f024.csv"  # Example path
    nbm_file = "data/nbm/f024/KSLC_2020_2025_f024.csv"  # Example path
    
    if Path(forecast_file).exists() and Path(nbm_file).exists():
        # Load a subset of data for demonstration
        forecast_df = pd.read_csv(forecast_file)
        nbm_df = pd.read_csv(nbm_file)
        
        # Convert datetime columns
        forecast_df['valid_datetime'] = pd.to_datetime(forecast_df['valid_datetime'])
        nbm_df['valid_datetime'] = pd.to_datetime(nbm_df['valid_datetime'])
        
        # Set index
        forecast_df = forecast_df.set_index(['valid_datetime', 'sid'])
        nbm_df = nbm_df.set_index(['valid_datetime', 'sid'])
        
        # Take a recent subset for prediction
        forecast_df = forecast_df.tail(100)  # Last 100 records
        nbm_df = nbm_df.tail(100)
        
        print(f"Loaded forecast data: {forecast_df.shape}")
        print(f"Loaded NBM data: {nbm_df.shape}")
        
        return forecast_df, nbm_df
    else:
        print(f"Example data files not found. Please update paths in load_new_data_example()")
        return None, None

def main():
    """Main function to demonstrate model application."""
    
    print("=== APPLYING TRAINED GEFS ML MODEL ===")
    
    # Specify target type - should match your trained model
    target_type = 'tmax'  # or 'tmin'
    
    try:
        # Load the trained model and metadata
        print(f"\n=== LOADING TRAINED MODEL ({target_type.upper()}) ===")
        model, metadata = load_model_and_metadata(target_type=target_type)
        
        # Print model information
        model_info = metadata['model_info']
        print(f"Model type: {model_info['model_type']}")
        print(f"Training timestamp: {model_info['training_timestamp']}")
        print(f"Target: {model_info['target_description']}")
        print(f"Features used: {metadata['features']['n_features']}")
        
        # Load new data for prediction
        print(f"\n=== LOADING NEW DATA ===")
        new_forecast_df, new_nbm_df = load_new_data_example()
        
        if new_forecast_df is not None and new_nbm_df is not None:
            # Apply model to new data
            print(f"\n=== MAKING PREDICTIONS ===")
            predictions_df, prediction_info = apply_model_to_new_data(
                model, metadata, new_forecast_df, new_nbm_df
            )
            
            # Display results
            print(f"\n=== PREDICTION RESULTS ===")
            print(f"Generated predictions for {len(predictions_df)} time points")
            print(f"\nSample predictions:")
            print(predictions_df.head(10))
            
            # Save predictions
            output_dir = Path('predictions')
            output_dir.mkdir(exist_ok=True)
            
            output_file = output_dir / f'predictions_{target_type}_{pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")}.csv'
            predictions_df.to_csv(output_file)
            print(f"\nPredictions saved to: {output_file}")
            
            # Show basic statistics
            print(f"\n=== PREDICTION STATISTICS ===")
            print(f"Predicted {target_type}:")
            print(f"  Mean: {predictions_df['predicted'].mean():.2f}°C")
            print(f"  Std:  {predictions_df['predicted'].std():.2f}°C")
            print(f"  Min:  {predictions_df['predicted'].min():.2f}°C")
            print(f"  Max:  {predictions_df['predicted'].max():.2f}°C")
            
            if 'nbm_baseline' in predictions_df.columns:
                print(f"\nNBM Baseline:")
                print(f"  Mean: {predictions_df['nbm_baseline'].mean():.2f}°C")
                print(f"  Std:  {predictions_df['nbm_baseline'].std():.2f}°C")
                
                # Calculate difference
                diff = predictions_df['predicted'] - predictions_df['nbm_baseline']
                print(f"\nML vs NBM Difference:")
                print(f"  Mean difference: {diff.mean():.2f}°C")
                print(f"  Std difference:  {diff.std():.2f}°C")
        
        else:
            print("No data loaded. Please check data paths and try again.")
            
    except FileNotFoundError as e:
        print(f"Error: Trained model not found. Please run gefs_ml_trainer.py first to train a model.")
        print(f"Details: {e}")
    except Exception as e:
        print(f"Error applying model: {e}")
        raise

if __name__ == "__main__":
    main()
